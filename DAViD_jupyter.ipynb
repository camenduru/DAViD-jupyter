{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github"
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/camenduru/SeedVR2-jupyter/blob/main/SeedVR2_jupyter.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /content\n",
    "!GIT_LFS_SKIP_SMUDGE=1 git clone --depth 1 --branch main https://github.com/microsoft/DAViD\n",
    "\n",
    "!wget https://facesyntheticspubwedata.z6.web.core.windows.net/iccv-2025/models/multi-task-model-vitl16_384.onnx\n",
    "!wget https://huggingface.co/uf/OmniAvatar_Assets/resolve/main/img.png\n",
    "\n",
    "%cd /content/DAViD\n",
    "!pip install -r requirement.txt\n",
    "!pip install onnxruntime-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from typing import Optional\n",
    "\n",
    "sys.path.append(os.path.join(os.getcwd(), \"runtime\"))\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from depth_estimator import RelativeDepthEstimator\n",
    "from multi_task_estimator import MultiTaskEstimator\n",
    "from soft_foreground_segmenter import SoftForegroundSegmenter\n",
    "from surface_normal_estimator import SurfaceNormalEstimator\n",
    "from visualize import (\n",
    "    create_concatenated_display,\n",
    "    visualize_foreground,\n",
    "    visualize_normal_maps,\n",
    "    visualize_relative_depth_map,\n",
    ")\n",
    "\n",
    "\n",
    "def generate(\n",
    "    image_path: str,\n",
    "    multitask_model: Optional[str] = None,\n",
    "    depth_model: Optional[str] = None,\n",
    "    foreground_model: Optional[str] = None,\n",
    "    normal_model: Optional[str] = None,\n",
    "    output_path: Optional[str] = None,\n",
    "    headless: bool = False,\n",
    ") -> None:\n",
    "    \"\"\"Main function to run the demo with input arguments.\n",
    "\n",
    "    Args:\n",
    "        image_path (str): Path to the input image.\n",
    "        multitask_model (Optional[str]): Path to the multi-task ONNX model. Defaults to None.\n",
    "        depth_model (Optional[str]): Path to the depth estimation ONNX model. Defaults to None.\n",
    "        foreground_model (Optional[str]): Path to the foreground segmentation ONNX model. Defaults to None.\n",
    "        normal_model (Optional[str]): Path to the surface normal estimation ONNX model. Defaults to None.\n",
    "        output_path (Optional[str]): Directory to save output results. Defaults to None.\n",
    "        headless (bool): Run without GUI display (for headless servers). Defaults to False.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(image_path):\n",
    "        print(f\"Error: Image not found: {image_path}\")\n",
    "        return\n",
    "\n",
    "    multitask_available = multitask_model and os.path.exists(multitask_model)\n",
    "    depth_available = depth_model and os.path.exists(depth_model)\n",
    "    foreground_available = foreground_model and os.path.exists(foreground_model)\n",
    "    normal_available = normal_model and os.path.exists(normal_model)\n",
    "\n",
    "    if not (\n",
    "        multitask_available\n",
    "        or depth_available\n",
    "        or foreground_available\n",
    "        or normal_available\n",
    "    ):\n",
    "        print(\"Error: At least one model must be provided and exist.\")\n",
    "        print(\"Available options:\")\n",
    "        print(\"  multitask_model: Multi-task model for all tasks\")\n",
    "        print(\"  depth_model: Individual depth estimation model\")\n",
    "        print(\"  foreground_model: Individual foreground segmentation model\")\n",
    "        print(\"  normal_model: Individual surface normal estimation model\")\n",
    "        return\n",
    "\n",
    "    if output_path and not os.path.exists(output_path):\n",
    "        os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        print(f\"Error: Could not read the image from {image_path}\")\n",
    "        return\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    has_individual_models = (\n",
    "        (depth_model and os.path.exists(depth_model))\n",
    "        or (foreground_model and os.path.exists(foreground_model))\n",
    "        or (normal_model and os.path.exists(normal_model))\n",
    "    )\n",
    "\n",
    "    if has_individual_models:\n",
    "        results[\"individual\"] = process_with_individual_models(\n",
    "            image, depth_model, foreground_model, normal_model\n",
    "        )\n",
    "    if multitask_model:\n",
    "        results[\"multitask\"] = process_with_multitask_model(image, multitask_model)\n",
    "\n",
    "    display_results(image, results, output_path, headless)\n",
    "\n",
    "\n",
    "def process_with_individual_models(\n",
    "    image: np.ndarray,\n",
    "    depth_model: Optional[str] = None,\n",
    "    foreground_model: Optional[str] = None,\n",
    "    normal_model: Optional[str] = None,\n",
    "):\n",
    "    \"\"\"Process image using individual models for each task.\"\"\"\n",
    "    results = {}\n",
    "\n",
    "    if depth_model:\n",
    "        depth_estimator = RelativeDepthEstimator(\n",
    "            onnx_model=depth_model, is_inverse=True\n",
    "        )\n",
    "        results[\"depth\"] = depth_estimator.estimate_relative_depth(image)\n",
    "\n",
    "    if foreground_model:\n",
    "        foreground_segmenter = SoftForegroundSegmenter(onnx_model=foreground_model)\n",
    "        results[\"foreground\"] = foreground_segmenter.estimate_foreground_segmentation(\n",
    "            image\n",
    "        )\n",
    "\n",
    "    if normal_model:\n",
    "        normal_estimator = SurfaceNormalEstimator(onnx_model=normal_model)\n",
    "        results[\"normal\"] = normal_estimator.estimate_normal(image)\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def process_with_multitask_model(image: np.ndarray, multitask_model: str):\n",
    "    \"\"\"Process image using multi-task model.\"\"\"\n",
    "    multitask_estimator = MultiTaskEstimator(\n",
    "        onnx_model=multitask_model, is_inverse_depth=False\n",
    "    )\n",
    "    return multitask_estimator.estimate_all_tasks(image)\n",
    "\n",
    "\n",
    "def display_results(\n",
    "    image: np.ndarray,\n",
    "    results: dict[str, np.ndarray],\n",
    "    output_path: Optional[str] = None,\n",
    "    headless: bool = False,\n",
    "):\n",
    "    \"\"\"Display results.\"\"\"\n",
    "    if \"individual\" in results:\n",
    "        individual_result = display_single_model_results(\n",
    "            image, results[\"individual\"], prefix=\"Individual\"\n",
    "        )\n",
    "        if output_path:\n",
    "            cv2.imwrite(\n",
    "                os.path.join(output_path, \"individual_results.png\"),\n",
    "                individual_result,\n",
    "            )\n",
    "    if \"multitask\" in results:\n",
    "        multitask_results = results[\"multitask\"]\n",
    "        multitask_result = display_single_model_results(\n",
    "            image, multitask_results, prefix=\"Multi-task\"\n",
    "        )\n",
    "        if output_path:\n",
    "            cv2.imwrite(\n",
    "                os.path.join(output_path, \"multitask_results.png\"),\n",
    "                multitask_result,\n",
    "            )\n",
    "\n",
    "    if \"individual\" in results and \"multitask\" in results:\n",
    "        if len(results[\"individual\"]) == len(results[\"multitask\"]):\n",
    "            compare_results = cv2.vconcat([individual_result, multitask_result])\n",
    "            if output_path:\n",
    "                cv2.imwrite(\n",
    "                    os.path.join(output_path, \"comparison_results.png\"),\n",
    "                    compare_results,\n",
    "                )\n",
    "\n",
    "    if not headless:\n",
    "        if (\n",
    "            \"individual\" in results\n",
    "            and \"multitask\" in results\n",
    "            and len(results[\"individual\"]) == len(results[\"multitask\"])\n",
    "        ):\n",
    "            cv2.imshow(\"Comparison: Individual vs Multi-task\", compare_results)\n",
    "        if \"individual\" in results:\n",
    "            cv2.imshow(\"Individual Model Results\", individual_result)\n",
    "        if \"multitask\" in results:\n",
    "            cv2.imshow(\"Multi-task Model Results\", multitask_result)\n",
    "\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "def display_single_model_results(image, model_results, prefix=\"\"):\n",
    "    \"\"\"\n",
    "    Display results from a single model (individual or multitask) by creating a concatenated visualization.\n",
    "\n",
    "    Args:\n",
    "        image (np.ndarray): Input image in BGR format (OpenCV-compatible).\n",
    "        model_results (dict): Dictionary containing model outputs (e.g., 'depth', 'foreground', 'normal').\n",
    "        prefix (str, optional): Prefix for visualization labels. Defaults to \"\".\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Concatenated visualization image in BGR format.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If input image is invalid or model_results is empty.\n",
    "        KeyError: If expected visualization functions are not defined.\n",
    "    \"\"\"\n",
    "    if not isinstance(image, np.ndarray) or image.size == 0:\n",
    "        raise ValueError(\"Invalid input image\")\n",
    "    if not model_results:\n",
    "        raise ValueError(\"model_results dictionary is empty\")\n",
    "\n",
    "    visualizations = [image]\n",
    "    labels = [\"Input Image\"]\n",
    "\n",
    "    foreground_mask = model_results.get(\"foreground\")\n",
    "\n",
    "    if \"depth\" in model_results:\n",
    "        depth_vis = visualize_relative_depth_map(image, model_results[\"depth\"], foreground_mask)\n",
    "        save_image(depth_vis, output_path=\"output\", filename=\"depth_vis.png\")\n",
    "        visualizations.append(depth_vis)\n",
    "        labels.append(f\"{prefix}Depth Map\")\n",
    "\n",
    "    if \"foreground\" in model_results:\n",
    "        foreground_vis = visualize_foreground(image, model_results[\"foreground\"])\n",
    "        save_image(foreground_vis, output_path=\"output\", filename=\"foreground_vis.png\")\n",
    "        visualizations.append(foreground_vis)\n",
    "        labels.append(f\"{prefix}Foreground Mask\")\n",
    "\n",
    "    if \"normal\" in model_results:\n",
    "        normal_vis = visualize_normal_maps(image, model_results[\"normal\"], foreground_mask)\n",
    "        save_image(normal_vis, output_path=\"output\", filename=\"normal_vis.png\")\n",
    "        visualizations.append(normal_vis)\n",
    "        labels.append(f\"{prefix}Normal Map\")\n",
    "\n",
    "    result = create_concatenated_display(visualizations, labels, downscale=2)\n",
    "    return result\n",
    "\n",
    "def save_image(image, output_path, filename=\"individual_results.png\"):\n",
    "    \"\"\"\n",
    "    Save an image to the specified path using OpenCV.\n",
    "\n",
    "    Args:\n",
    "        image (np.ndarray): Image to save (BGR format).\n",
    "        output_path (str): Directory path to save the image.\n",
    "        filename (str, optional): Output filename. Defaults to \"individual_results.png\".\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If output_path is invalid or image is invalid.\n",
    "    \"\"\"\n",
    "    if not os.path.isdir(output_path):\n",
    "        raise ValueError(f\"Output directory does not exist: {output_path}\")\n",
    "    if not isinstance(image, np.ndarray) or image.size == 0:\n",
    "        raise ValueError(\"Invalid image for saving\")\n",
    "\n",
    "    output_file = os.path.join(output_path, filename)\n",
    "    cv2.imwrite(output_file, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate(image_path=\"/content/DAViD/img.png\",\n",
    "            multitask_model=\"/content/DAViD/multi-task-model-vitl16_384.onnx\",\n",
    "            depth_model=None,\n",
    "            foreground_model=None,\n",
    "            normal_model=None,\n",
    "            output_path=\"output\",\n",
    "            headless=True,)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
